{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9258072,"sourceType":"datasetVersion","datasetId":5601552}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --upgrade openai","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This command is used to install or upgrade the OpenAI Python library using pip, which is the package installer for Python. Let's break it down:\n\n- `!` at the beginning is typically used in Jupyter notebooks to run shell commands. In a regular Python environment or command line, you would omit this.\n\n- `pip` is the package management system used to install and manage software packages written in Python.\n\n- `install` is the pip command to install a package.\n\n- `--upgrade` is an option that tells pip to upgrade the package to the latest version if it's already installed. If the package isn't installed, it will simply install the latest version.\n\n- `openai` is the name of the package being installed or upgraded. This is the official Python client library for the OpenAI API, which allows developers to interact with various OpenAI services like GPT-3, DALL-E, and others.\n\nBy running this command, you're ensuring that you have the latest version of the OpenAI Python library installed in your Python environment. This is often important to access the most recent features and bug fixes in the OpenAI API client.","metadata":{}},{"cell_type":"code","source":"from openai import OpenAI\nfrom kaggle_secrets import UserSecretsClient\nimport time ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This code consists of three import statements. Let's examine each one:\n\n1. `from openai import OpenAI`:\n   - This line imports the `OpenAI` class from the `openai` module.\n   - The `OpenAI` class is likely the main interface for interacting with OpenAI's API services.\n   - This import suggests that the code will be using OpenAI's services, such as GPT models, in some capacity.\n\n2. `from kaggle_secrets import UserSecretsClient`:\n   - This imports the `UserSecretsClient` class from the `kaggle_secrets` module.\n   - Kaggle is a platform for data science and machine learning competitions.\n   - The `UserSecretsClient` is typically used to securely access user-specific secrets or API keys within a Kaggle environment.\n   - This import indicates that the code is likely running in a Kaggle environment and will need to access some secret information, possibly an API key for OpenAI.\n\n3. `import time`:\n   - This imports the entire `time` module, which provides various time-related functions.\n   - The `time` module is part of Python's standard library.\n   - Common uses of the `time` module include adding delays, measuring execution time, or working with timestamps.\n\nOverall, this code is setting up the necessary imports for a script that will likely:\n1. Interact with OpenAI's API\n2. Access some secret information (probably an API key) stored in the Kaggle environment\n3. Potentially involve some time-related operations, such as adding delays between API calls or measuring execution time","metadata":{}},{"cell_type":"code","source":"user_secrets = UserSecretsClient()\n\nclient = OpenAI(api_key=user_secrets.get_secret(\"openaivision\"))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This code is initializing two important objects for interacting with the OpenAI API in a Kaggle environment. Let's examine each line:\n\n1. `user_secrets = UserSecretsClient()`:\n   - This line creates an instance of the `UserSecretsClient` class and assigns it to the variable `user_secrets`.\n   - The `UserSecretsClient` is a utility provided by Kaggle to securely access user-specific secrets or API keys.\n   - By instantiating this client, the code can now retrieve secrets that have been stored in the Kaggle environment.\n\n2. `client = OpenAI(api_key=user_secrets.get_secret(\"openaivision\"))`:\n   - This line creates an instance of the `OpenAI` class and assigns it to the variable `client`.\n   - The `OpenAI` class is initialized with an `api_key` parameter.\n   - The value for `api_key` is obtained by calling `user_secrets.get_secret(\"openaivision\")`.\n     - This method call retrieves a secret value associated with the key \"openaivision\" from the Kaggle secrets storage.\n     - \"openaivision\" is likely the name given to the stored OpenAI API key in the Kaggle environment.\n\nThe purpose of this code is to:\n1. Set up secure access to the user's secrets in the Kaggle environment.\n2. Retrieve the OpenAI API key that has been stored securely in Kaggle.\n3. Initialize the OpenAI client with this API key, allowing the code to make authenticated requests to OpenAI's services.\n\nThis approach is a security best practice because it avoids hardcoding the API key directly in the script. Instead, it retrieves the key from a secure storage mechanism provided by the platform (in this case, Kaggle).\n\nAfter executing this code, the `client` object can be used to interact with OpenAI's API services, such as making requests to language models or other AI services provided by OpenAI.\n","metadata":{}},{"cell_type":"code","source":"\nassistant = client.beta.assistants.create(\n    name = \"helper2\",\n    instructions = \"Your role as 'Business AI Guide' is to assist users with questions \\\n                    and explanations about Artificial Intelligence (AI) and \\\n                    Machine Learning (ML), tailored for business professionals. \\\n                    You should simplify complex technical information into clear,\\\n                    business-friendly language, avoiding technical jargon. \\\n                    Maintain a formal tone in your communications, being \\\n                    informative and patient, ensuring clarity for users\\\n                    without a technical background. Avoid detailed \\\n                    technical explanations unless specifically requested. \\\n                    Refrain from discussing politics or current affairs, \\\n                    and avoid speculating. If uncertain about an answer,\\\n                    respond with 'I do not know.' Limit yourself to asking \\\n                    for clarification only once per query; if the query \\\n                    remains unclear after that, provide the best answer \\\n                    you can, filling in any missing details as needed.\",\n     model = \"gpt-4o-mini\",\n\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This code is creating a new AI assistant using OpenAI's Assistants API. Let's examine each part:\n\n1. `client.beta.assistants.create()`:\n   - This method call creates a new assistant using the OpenAI API.\n   - The `beta` namespace indicates that this feature might still be in beta testing.\n\n2. `name=\"helper2\"`:\n   - This sets the name of the assistant to \"helper2\".\n\n3. `instructions=\"...\"`:\n   - This provides detailed instructions for the assistant's behavior and purpose.\n   - The instructions specify that the assistant should:\n     - Answer questions about the Digital Services Act in the EU\n     - Explain legal issues in non-technical language for a general audience\n     - Be friendly but formal\n     - Avoid jargon\n     - Offer clarifications, not opinions\n\n4. `tools=[{\"type\":\"retrieval\"}]`:\n   - This specifies the tools the assistant can use.\n   - The \"retrieval\" tool allows the assistant to access and use information from files that have been uploaded.\n\n5. `model=\"gpt-4o-mini\"`:\n   - This specifies the underlying language model to be used for the assistant.\n   - \"gpt-4o-mini\" appears to be a custom or non-standard model name. Typically, you might see names like \"gpt-4\" or \"gpt-3.5-turbo\". This could be a typo or a custom model designation.\n\n6. `file_ids=[file.id]`:\n   - This links the previously uploaded file (from the `file` object we created earlier) to this assistant.\n   - The assistant will be able to access and use the information in this file when answering questions.\n\n7. The result is assigned to the variable `assistant`:\n   - This variable will contain information about the created assistant, including its unique identifier.\n\nThis code is setting up a specialized AI assistant that can answer questions about the Digital Services Act in the EU. It's designed to explain complex legal issues in simple terms, maintaining a friendly but formal tone. The assistant will use the file that was previously uploaded (likely containing information about the Digital Services Act) to help answer questions.\n","metadata":{"execution":{"iopub.status.busy":"2024-08-27T23:34:18.464490Z","iopub.execute_input":"2024-08-27T23:34:18.464885Z","iopub.status.idle":"2024-08-27T23:34:18.484597Z","shell.execute_reply.started":"2024-08-27T23:34:18.464847Z","shell.execute_reply":"2024-08-27T23:34:18.483212Z"}}},{"cell_type":"code","source":"thread = client.beta.threads.create()\nprint(thread)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nThis code is creating a new thread using OpenAI's Assistants API. Let's break it down:\n\n1. `client.beta.threads.create()`:\n   - This method call creates a new thread using the OpenAI API.\n   - The `beta` namespace again indicates that this feature might still be in beta testing.\n   - A \"thread\" in the context of OpenAI's Assistants API represents a conversation or an ongoing interaction between a user and an assistant.\n\n2. The result of this creation is assigned to the variable `thread`:\n   - This variable will contain information about the newly created thread, including its unique identifier.\n\n3. `print(thread)`:\n   - This line prints the `thread` object to the console.\n   - It will likely display a JSON-like representation of the thread, including details such as its ID and creation timestamp.\n\nThe purpose of creating a thread is to maintain context and continuity in a conversation with an AI assistant. Here's why this is important:\n\n- Stateful Conversations: Threads allow for stateful conversations, meaning the assistant can remember and refer back to earlier parts of the conversation.\n\n- Organization: Each thread can represent a distinct conversation or task, helping to organize interactions with the assistant.\n\n- Context Management: The thread keeps track of the conversation's context, allowing the assistant to provide more relevant and coherent responses over time.\n\nTypically, after creating a thread, you would use it to add messages and generate responses from the assistant. The general flow might look like this:\n\n1. Create a thread (as shown in this code snippet)\n2. Add user messages to the thread\n3. Run the assistant on the thread to generate responses\n4. Retrieve and display the assistant's responses\n\n","metadata":{}},{"cell_type":"code","source":"\n\nmessage = client.beta.threads.messages.create(\n    thread_id = thread.id,\n    role = \"user\",\n    content = \"What is generative AI?\"\n\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\nThis code is creating a new message within the existing thread using OpenAI's Assistants API. Let's examine each part:\n\n1. `client.beta.threads.messages.create()`:\n   - This method call creates a new message in a specific thread.\n   - It's part of the `beta` namespace, indicating it might still be in beta testing.\n\n2. `thread_id=thread.id`:\n   - This parameter specifies which thread the message should be added to.\n   - It uses the `id` of the `thread` object we created earlier in the conversation.\n   - This ensures that the new message is part of the ongoing conversation.\n\n3. `role=\"user\"`:\n   - This parameter sets the role of the message sender to \"user\".\n   - In the context of AI assistants, messages typically have either a \"user\" or \"assistant\" role to differentiate between human input and AI responses.\n\n4. `content=\"What is generative AI?\"`:\n   - This is the actual content of the message.\n   - In this case, it's a new question about generative AI.\n\n5. The result is assigned to the variable `message`:\n   - This variable will contain information about the newly created message, including its unique identifier and other metadata.\n\n\nAfter adding this message, you would typically create a new run (as we saw in previous code snippets) to have the assistant process this question and generate a response.\n","metadata":{}},{"cell_type":"code","source":"\nrun = client.beta.threads.runs.create(\n    thread_id = thread.id,\n    assistant_id= assistant.id\n\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This code is initiating a \"run\" using OpenAI's Assistants API. Let's examine each part:\n\n1. `client.beta.threads.runs.create()`:\n   - This method call creates a new \"run\" on a specific thread.\n   - A \"run\" in this context means executing the assistant on the thread to generate responses to the messages in that thread.\n   - The `beta` namespace indicates that this feature might still be in beta testing.\n\n2. `thread_id = thread.id`:\n   - This parameter specifies which thread the run should be executed on.\n   - It uses the `id` of the `thread` object we created earlier.\n\n3. `assistant_id = assistant.id`:\n   - This parameter specifies which assistant should be used for this run.\n   - It uses the `id` of the `assistant` object we created earlier in the code.\n\n4. The result is assigned to the variable `run`:\n   - This variable will contain information about the newly created run, including its unique identifier and status.\n\nThe significance of this operation in the context of using the Assistants API is:\n\n1. It initiates the process of the assistant analyzing the messages in the thread and generating responses.\n2. It connects the specific assistant we created (with its custom instructions and associated files) to the conversation thread containing the user's questions.\n3. It starts an asynchronous process, meaning the assistant will work on generating responses in the background.\n\nAfter creating a run, the typical next steps would be:\n\n1. Check the status of the run periodically to see when it's completed.\n2. Once completed, retrieve the assistant's responses from the thread.\n3. Process or display these responses to the user.\n\nThis asynchronous nature allows for handling potentially time-consuming operations, such as analyzing large documents or generating detailed responses, without blocking the main execution of your program.\n","metadata":{}},{"cell_type":"code","source":"while True:\n    run_status = client.beta.threads.runs.retrieve(thread_id=thread.id,run_id=run.id)\n    time.sleep(10)\n    if run_status.status == 'completed':\n        messages = client.beta.threads.messages.list(thread_id=thread.id)\n        break\n    else:\n        time.sleep(2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nThis code is implementing a polling mechanism to check the status of the run we initiated earlier. Let's examine each part:\n\n1. `while True:`:\n   - This starts an infinite loop that will continue until explicitly broken.\n\n2. `run_status = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)`:\n   - This retrieves the current status of the run we started earlier.\n   - It uses both the `thread.id` and `run.id` to uniquely identify the specific run we're interested in.\n\n3. `time.sleep(10)`:\n   - This pauses the execution for 10 seconds before checking the run status.\n   - This helps to avoid making too frequent API calls.\n\n4. `if run_status.status == 'completed':`:\n   - This checks if the run has completed.\n\n5. If the run is completed:\n   - `messages = client.beta.threads.messages.list(thread_id=thread.id)`:\n     - This retrieves all messages in the thread, including the assistant's newly generated responses.\n   - `break`:\n     - This exits the while loop since we've got our result.\n\n6. If the run is not completed:\n   - `time.sleep(2)`:\n     - This adds a short 2-second pause before the next iteration of the loop.\n\nThe significance of this code:\n\n1. It implements a polling mechanism to periodically check the status of the assistant's run.\n2. It's designed to wait until the assistant has finished generating its response before proceeding.\n3. Once the run is completed, it retrieves all messages in the thread, which will include the assistant's new responses.\n4. The use of `time.sleep()` helps to manage the rate of API calls, preventing too frequent requests.\n\nThis approach is useful because:\n- It allows for handling potentially long-running operations without blocking the entire program.\n- It provides a way to wait for the assistant's response without knowing exactly how long it will take.\n- It retrieves the final results once they're ready.\n\nAfter this loop completes, the `messages` variable will contain all the messages in the thread, including the assistant's newly generated responses to the user's questions.\n","metadata":{}},{"cell_type":"code","source":"for message in reversed(messages.data):\n    print(message.role + \":\" + message.content[0].text.value)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nThis code is iterating through the messages retrieved from the thread and printing them out. Let's examine each part:\n\n1. `reversed(messages.data)`:\n   - `messages.data` likely contains a list of message objects returned from the API.\n   - `reversed()` is a Python built-in function that returns a reverse iterator of the sequence.\n   - This means the loop will start with the most recent message and work backwards.\n\n2. `for message in ...`:\n   - This sets up a loop to iterate through each message in the reversed list.\n\n3. `print(message.role + \":\" + message.content[0].text.value)`:\n   - This line prints information for each message:\n     - `message.role`: This is likely either \"user\" or \"assistant\", indicating who sent the message.\n     - \":\": A colon is added as a separator.\n     - `message.content[0].text.value`: This accesses the text content of the message.\n       - The `[0]` suggests that `content` might be a list, possibly allowing for multiple content parts in a message.\n       - `.text.value` further accesses the actual text value of the content.\n\nThe significance of this code:\n\n1. It displays the conversation in chronological order, starting with the most recent message and working backwards.\n2. It provides a simple way to see the back-and-forth between the user and the assistant.\n3. It formats the output in a \"role: message\" format, making it easy to distinguish between user inputs and assistant responses.\n\nThis approach is useful because:\n- It allows you to review the entire conversation, including both the user's questions and the assistant's responses.\n- Starting with the most recent message (by using `reversed()`) can be helpful if you're most interested in the latest response.\n- The simple formatting makes it easy to read and understand the flow of the conversation.\n\n\nThis code provides a straightforward way to display the conversation history, which can be particularly useful for debugging, logging, or presenting the results of the interaction with the AI assistant.","metadata":{}}]}