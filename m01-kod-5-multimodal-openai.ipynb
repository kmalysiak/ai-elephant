{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##### !pip install --upgrade openai pytubefix tiktoken moviepy","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-08-30T13:51:15.547635Z","iopub.execute_input":"2024-08-30T13:51:15.548808Z","iopub.status.idle":"2024-08-30T13:52:05.673169Z","shell.execute_reply.started":"2024-08-30T13:51:15.548762Z","shell.execute_reply":"2024-08-30T13:52:05.671505Z"}}},{"cell_type":"markdown","source":"This command is installing and upgrading several Python packages using pip, the Python package installer. Let's break it down:\n\n1. `!pip install`: This is a command to install packages. The `!` at the beginning is typically used in Jupyter notebooks to run shell commands.\n\n2. `--upgrade`: This flag tells pip to upgrade the packages to their latest versions if they're already installed.\n\n3. The packages being installed/upgraded are:\n\n   - `openai`: The official Python library for the OpenAI API, used for interacting with OpenAI's language models and other AI services.\n   \n   - `pytubefix`: A fork of the pytube library, used for downloading YouTube videos. The \"fix\" version likely includes some patches or improvements over the original pytube.\n   \n   - `tiktoken`: A fast BPE (Byte Pair Encoding) tokenizer, often used with OpenAI's models for text processing tasks.\n   \n   - `moviepy`: A Python library for video editing and manipulation.\n\nThis combination of packages suggests that the user might be working on a project involving AI (possibly using OpenAI's services), YouTube video downloading, text processing, and video editing.","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\nimport numpy as np\nimport pandas as pd\nimport os\n\nfrom openai import OpenAI\nimport openai \n\n\nfrom pytubefix import YouTube\nfrom pytubefix.cli import on_progress\n \nfrom moviepy.editor import VideoFileClip\nfrom moviepy.video.io.ffmpeg_tools import ffmpeg_extract_audio, ffmpeg_extract_subclip\n\nimport tiktoken\n\nimport IPython","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-30T13:52:05.676128Z","iopub.execute_input":"2024-08-30T13:52:05.677174Z","iopub.status.idle":"2024-08-30T13:52:08.841764Z","shell.execute_reply.started":"2024-08-30T13:52:05.677122Z","shell.execute_reply":"2024-08-30T13:52:08.840754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This code block is importing various Python libraries and modules. Let's break it down:\n\n1. `from kaggle_secrets import UserSecretsClient`: \n   This imports a client for managing user secrets in Kaggle notebooks, likely used for securely storing API keys or other sensitive information.\n\n2. `import numpy as np`:\n   Imports NumPy, a fundamental package for scientific computing in Python, with the alias 'np'.\n\n3. `import pandas as pd`:\n   Imports Pandas, a data manipulation and analysis library, with the alias 'pd'.\n\n4. `import os`:\n   Imports the OS module, which provides a way to use operating system-dependent functionality.\n\n5. `from openai import OpenAI`:\n   Imports the OpenAI class from the OpenAI library, used for interacting with OpenAI's API.\n\n6. `import openai`:\n   Imports the entire OpenAI module.\n\n7. `from pytubefix import YouTube`:\n   Imports the YouTube class from pytubefix, used for downloading YouTube videos.\n\n8. `from pytubefix.cli import on_progress`:\n   Imports a progress callback function from pytubefix's command-line interface module.\n\n9. `from moviepy.editor import VideoFileClip`:\n   Imports VideoFileClip from moviepy, used for video file operations.\n\n10. `from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_audio, ffmpeg_extract_subclip`:\n    Imports specific functions from moviepy's ffmpeg tools for audio extraction and video clipping.\n\n11. `import tiktoken`:\n    Imports tiktoken, a fast tokenizer often used with OpenAI's models.\n\n12. `import IPython`:\n    Imports IPython, which provides a rich toolkit to help you make the most of using Python interactively.\n\nThis set of imports suggests that the script is likely to perform tasks involving data analysis (numpy, pandas), API interactions with OpenAI, YouTube video downloading and processing, video and audio manipulation, and possibly some interactive or notebook-based operations (IPython).\n\n","metadata":{}},{"cell_type":"code","source":"class CFG:\n    model1 = \"gpt-4-vision-preview\"\n    device = 'cuda'\n","metadata":{"execution":{"iopub.status.busy":"2024-08-30T13:52:08.843103Z","iopub.execute_input":"2024-08-30T13:52:08.844068Z","iopub.status.idle":"2024-08-30T13:52:08.849419Z","shell.execute_reply.started":"2024-08-30T13:52:08.844033Z","shell.execute_reply":"2024-08-30T13:52:08.848092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# setup OpenAI API connection\nuser_secrets = UserSecretsClient()\napi_key=user_secrets.get_secret(\"openaivision\")\nos.environ['OPENAI_API_KEY']= api_key\nclient = OpenAI(api_key= api_key)","metadata":{"execution":{"iopub.status.busy":"2024-08-30T13:52:08.851634Z","iopub.execute_input":"2024-08-30T13:52:08.852575Z","iopub.status.idle":"2024-08-30T13:52:09.036979Z","shell.execute_reply.started":"2024-08-30T13:52:08.852531Z","shell.execute_reply":"2024-08-30T13:52:09.035917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This code block sets up the connection to the OpenAI API. Let's break it down line by line:\n\n1. `user_secrets = UserSecretsClient()`\n   This creates an instance of the UserSecretsClient, which is used to securely access user secrets (like API keys) in Kaggle notebooks.\n\n2. `api_key = user_secrets.get_secret(\"openaivision\")`\n   This retrieves a secret value named \"openaivision\" using the UserSecretsClient. This secret is likely the API key for OpenAI's services, specifically for their vision-related API.\n\n3. `os.environ['OPENAI_API_KEY'] = api_key`\n   This sets an environment variable named 'OPENAI_API_KEY' with the value of the api_key. Many libraries, including the OpenAI library, can automatically detect and use API keys set as environment variables.\n\n4. `client = OpenAI(api_key=api_key)`\n   This creates an instance of the OpenAI client, explicitly passing the api_key. This client can be used to make requests to OpenAI's API.\n\nThe purpose of this code is to securely set up the OpenAI API for use in the script. It's doing so in a way that's compatible with Kaggle's notebook environment, which provides a secure way to store and access API keys without exposing them in the code.\n\nBy setting the API key both as an environment variable and explicitly when creating the OpenAI client, the code ensures that the API key is available regardless of how different parts of the OpenAI library might try to access it.\n\nThis setup allows the script to make authenticated requests to OpenAI's API, likely for tasks involving AI models.","metadata":{}},{"cell_type":"markdown","source":"# Functions","metadata":{}},{"cell_type":"code","source":"def num_tokens_from_message(messages, tokens_per_message = 3, tokens_per_name = 1):\n    num_tokens = 0\n    for message in messages:\n        num_tokens += tokens_per_message\n        for key, value in message.items():\n            num_tokens += len(encoding.encode(value))\n            if key == \"name\":\n                num_tokens += tokens_per_name\n    num_tokens += 3\n    return num_tokens","metadata":{"execution":{"iopub.status.busy":"2024-08-30T13:52:09.039541Z","iopub.execute_input":"2024-08-30T13:52:09.039922Z","iopub.status.idle":"2024-08-30T13:52:09.047371Z","shell.execute_reply.started":"2024-08-30T13:52:09.039889Z","shell.execute_reply":"2024-08-30T13:52:09.046274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This function `num_tokens_from_message` is designed to estimate the number of tokens in a series of messages. It's likely used to calculate token usage for OpenAI's API, which often charges based on the number of tokens processed. Let's break it down:\n\n```python\ndef num_tokens_from_message(messages, tokens_per_message=3, tokens_per_name=1):\n```\n- This defines a function that takes a list of `messages` and two optional parameters:\n  - `tokens_per_message`: Defaults to 3, representing a fixed token cost per message.\n  - `tokens_per_name`: Defaults to 1, representing an additional token cost for names.\n\n```python\n    num_tokens = 0\n```\n- Initializes a counter for the total number of tokens.\n\n```python\n    for message in messages:\n        num_tokens += tokens_per_message\n```\n- Iterates through each message, adding the fixed cost (`tokens_per_message`) for each message.\n\n```python\n        for key, value in message.items():\n            num_tokens += len(encoding.encode(value))\n```\n- For each key-value pair in the message:\n  - It encodes the value using some encoding (likely defined elsewhere in the code, probably using `tiktoken`) and adds the length of the encoded value to the token count.\n\n```python\n            if key == \"name\":\n                num_tokens += tokens_per_name\n```\n- If the key is \"name\", it adds an additional token cost specified by `tokens_per_name`.\n\n```python\n    num_tokens += 3\n```\n- Adds 3 more tokens at the end. This might be for some fixed overhead in the API call.\n\n```python\n    return num_tokens\n```\n- Returns the total calculated number of tokens.\n\nThis function appears to be a custom implementation for estimating token usage, possibly tailored for a specific API or use case. It takes into account:\n1. A fixed cost per message\n2. The content length of each key-value pair in the messages\n3. An extra cost for 'name' fields\n4. A small fixed overhead\n\nThe actual encoding of the values is done using an `encoding` object, which is not defined in this snippet but is likely an instance of a tokenizer (probably from the `tiktoken` library, given the earlier imports).\n\nThis kind of function is useful for estimating costs or ensuring that API requests stay within token limits before sending them to the API.","metadata":{}},{"cell_type":"markdown","source":"# Transcript a video","metadata":{}},{"cell_type":"code","source":"video_url = \"https://www.youtube.com/watch?v=ssGKniyIUGk\"\n    \n    \n# Transcript a large video\nyt = YouTube(video_url, on_progress_callback = on_progress)\nprint(yt.title)\n \nys = yt.streams.get_highest_resolution()\nys.download()","metadata":{"execution":{"iopub.status.busy":"2024-08-30T13:52:09.048823Z","iopub.execute_input":"2024-08-30T13:52:09.049160Z","iopub.status.idle":"2024-08-30T13:52:11.042736Z","shell.execute_reply.started":"2024-08-30T13:52:09.049131Z","shell.execute_reply":"2024-08-30T13:52:11.041582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This code is using the `pytubefix` library to download a YouTube video. Let's break it down:\n\n```python\nvideo_url = \"https://www.youtube.com/watch?v=ssGKniyIUGk\"\n```\nThis line defines the URL of the YouTube video to be downloaded. In this case, it's a specific video with the ID \"ssGKniyIUGk\".\n\n```python\nyt = YouTube(video_url, on_progress_callback=on_progress)\n```\nThis creates a `YouTube` object from the `pytubefix` library. It takes two arguments:\n1. `video_url`: The URL of the video to be processed.\n2. `on_progress_callback=on_progress`: This sets a callback function to be called to report download progress. The `on_progress` function was imported earlier from `pytubefix.cli`.\n\n```python\nprint(yt.title)\n```\nThis line prints the title of the YouTube video. The `YouTube` object retrieves this information from the video's metadata.\n\n```python\nys = yt.streams.get_highest_resolution()\n```\nThis line gets the highest resolution stream available for the video. The `streams` attribute of the `YouTube` object contains all available streams (different formats and qualities), and `get_highest_resolution()` selects the stream with the highest video quality.\n\n```python\nys.download()\n```\nThis final line starts the download of the selected stream. By default, it will save the video in the current working directory with the video's title as the filename.\n\nIn summary, this code does the following:\n1. Specifies a YouTube video URL.\n2. Creates a `YouTube` object for that video, setting up progress reporting.\n3. Prints the video's title.\n4. Selects the highest quality version of the video available.\n5. Downloads that version of the video.\n","metadata":{}},{"cell_type":"code","source":"# brutal override - YT videos typically have emojis and whatnot - this is 2024 \n!cp *mp4 ./muhfile.mp4","metadata":{"execution":{"iopub.status.busy":"2024-08-30T13:54:36.385190Z","iopub.execute_input":"2024-08-30T13:54:36.386281Z","iopub.status.idle":"2024-08-30T13:54:37.577289Z","shell.execute_reply.started":"2024-08-30T13:54:36.386208Z","shell.execute_reply":"2024-08-30T13:54:37.575766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_video_file = \"muhfile.mp4\"\n\nvideo = VideoFileClip(input_video_file)\nvideo_duration = video.duration\nprint('time: ' + str(video_duration) + \" seconds\")\nprint('estimated cost: ' + str(video_duration * 0.006/60))","metadata":{"execution":{"iopub.status.busy":"2024-08-30T13:54:58.618712Z","iopub.execute_input":"2024-08-30T13:54:58.619152Z","iopub.status.idle":"2024-08-30T13:54:58.724346Z","shell.execute_reply.started":"2024-08-30T13:54:58.619112Z","shell.execute_reply":"2024-08-30T13:54:58.723238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This code snippet is using the `moviepy` library to analyze a video file and estimate the cost of processing it. Let's break it down line by line:\n\n```python\ninput_video_file = \"muhfile.mp4\"\n```\nThis line defines the name of the input video file. In this case, it's a file named \"muhfile.mp4\" which should be located in the same directory as the script (or the full path should be provided).\n\n```python\nvideo = VideoFileClip(input_video_file)\n```\nThis creates a `VideoFileClip` object from the `moviepy` library. It loads the video file specified by `input_video_file`. This object allows various operations and analyses on the video.\n\n```python\nvideo_duration = video.duration\n```\nThis retrieves the duration of the video in seconds and stores it in the `video_duration` variable.\n\n```python\nprint('time: ' + str(video_duration) + \" seconds\")\n```\nThis line prints the duration of the video in seconds.\n\n```python\nprint('estimated cost: ' + str(video_duration * 0.006/60))\n```\nThis line calculates and prints an estimated cost based on the video duration. Let's break down the calculation:\n\n- `video_duration * 0.006/60`: This calculates the cost.\n  - `0.006` seems to be a cost rate, possibly $0.006 per minute.\n  - The division by 60 converts the duration from seconds to minutes.\n\nSo, this is calculating the cost as if the rate is $0.006 per minute of video.\n\nOverall, this code snippet is:\n1. Loading a video file\n2. Determining its duration\n3. Printing the duration\n4. Calculating and printing an estimated cost based on the duration\n","metadata":{}},{"cell_type":"code","source":"# file size in bytes\nfile_size_bytes = os.path.getsize(input_video_file)\nfile_size_mb = file_size_bytes / (1024 * 1024)\nprint(f\"video size: {file_size_mb:.2f} MB\")","metadata":{"execution":{"iopub.status.busy":"2024-08-30T13:55:02.849767Z","iopub.execute_input":"2024-08-30T13:55:02.850139Z","iopub.status.idle":"2024-08-30T13:55:02.856490Z","shell.execute_reply.started":"2024-08-30T13:55:02.850111Z","shell.execute_reply":"2024-08-30T13:55:02.855309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This code snippet is used to determine and print the file size of the video. Let's break it down line by line:\n\n```python\nfile_size_bytes = os.path.getsize(input_video_file)\n```\n- `os.path.getsize()` is a function from the `os` module that returns the size of a file in bytes.\n- `input_video_file` is the path to the video file (which was defined earlier as \"muhfile.mp4\").\n- This line gets the size of the video file in bytes and stores it in `file_size_bytes`.\n\n```python\nfile_size_mb = file_size_bytes / (1024 * 1024)\n```\n- This line converts the file size from bytes to megabytes (MB).\n- The conversion is done by dividing the number of bytes by 1024 twice:\n  - First 1024 converts bytes to kilobytes\n  - Second 1024 converts kilobytes to megabytes\n- The result is stored in `file_size_mb`.\n\n```python\nprint(f\"video size: {file_size_mb:.2f} MB\")\n```\n- This line prints the file size in MB.\n- It uses an f-string (formatted string literal) for easy formatting.\n- `{file_size_mb:.2f}` formats `file_size_mb` to display with 2 decimal places.\n- The output will look something like: \"video size: 123.45 MB\"\n\nIn summary, this code snippet:\n1. Gets the size of the video file in bytes\n2. Converts the size from bytes to megabytes\n3. Prints the size in megabytes, rounded to two decimal places\n\nThis information can be useful for various reasons, such as:\n- Estimating storage requirements\n- Checking if the file size is within acceptable limits for processing\n- Providing information to the user about the video they're working with\n- Potentially using the file size to estimate processing time or costs for certain operations\n\n","metadata":{}},{"cell_type":"code","source":"# max size is 25 MB \n# -> https://community.openai.com/t/whisper-api-how-to-upload-file-that-larger-than-25mb/693285\nlimit_size_mb = 25\n\n# how many chunks will we need?\nnof_chunks = int(file_size_mb /limit_size_mb )  + 1\nprint(\"We will need: \" + str(nof_chunks) + \" chunks\")\n\n# min duration per chunk\nsplit = video_duration // nof_chunks","metadata":{"execution":{"iopub.status.busy":"2024-08-30T13:55:04.927436Z","iopub.execute_input":"2024-08-30T13:55:04.927860Z","iopub.status.idle":"2024-08-30T13:55:04.935132Z","shell.execute_reply.started":"2024-08-30T13:55:04.927822Z","shell.execute_reply":"2024-08-30T13:55:04.933898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This code snippet is calculating how to split a video file into chunks that meet a specific size limit. Let's break it down:\n\n```python\nlimit_size_mb = 25\n```\nThis sets the maximum allowed size for each chunk to 25 MB. The comment above mentions that this limit is related to the OpenAI Whisper API, which has a 25 MB file size limit.\n\n```python\nnof_chunks = int(file_size_mb / limit_size_mb) + 1\n```\nThis calculates the number of chunks needed:\n- `file_size_mb / limit_size_mb` divides the total file size by the size limit.\n- `int()` rounds down to the nearest integer.\n- `+ 1` ensures that there's always at least one chunk, and accounts for any remainder.\n\nFor example, if the file is 30 MB, this would calculate 2 chunks (30 / 25 = 1.2, rounded down to 1, then +1 = 2).\n\n```python\nprint(\"We will need: \" + str(nof_chunks) + \" chunks\")\n```\nThis prints the number of chunks that will be needed.\n\n```python\nsplit = video_duration // nof_chunks\n```\nThis calculates the duration of each chunk:\n- `video_duration` is the total duration of the video (calculated earlier).\n- `//` is integer division (rounds down).\n- This divides the total duration evenly among the chunks.\n\nFor example, if the video is 100 seconds long and we need 2 chunks, each chunk would be 50 seconds.\n\nIn summary, this code is doing the following:\n1. Setting a maximum chunk size of 25 MB (based on an API limitation).\n2. Calculating how many chunks are needed to split the video file into pieces no larger than 25 MB.\n3. Printing the number of chunks needed.\n4. Calculating how long each chunk should be in terms of video duration.\n\nThis approach allows processing of large video files by breaking them into smaller pieces that can be handled by APIs or processes with file size limitations. It's a common technique when working with large media files, especially when using services with upload size restrictions.","metadata":{}},{"cell_type":"code","source":"# split the video\nsplit_time = []\nfor ii in range(nof_chunks):\n    split_time.append(split * ii)\nsplit_time.append(video_duration)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-30T13:55:08.570719Z","iopub.execute_input":"2024-08-30T13:55:08.571127Z","iopub.status.idle":"2024-08-30T13:55:08.578850Z","shell.execute_reply.started":"2024-08-30T13:55:08.571091Z","shell.execute_reply":"2024-08-30T13:55:08.576176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This code snippet is creating a list of time points to split the video. Let's break it down:\n\n```python\nsplit_time = []\n```\nThis initializes an empty list called `split_time` that will store the time points for splitting the video.\n\n```python\nfor ii in range(nof_chunks):\n    split_time.append(split * ii)\n```\nThis is a loop that runs `nof_chunks` times (remember, `nof_chunks` was calculated earlier based on the file size).\n\nIn each iteration:\n- `ii` goes from 0 to `nof_chunks - 1`\n- `split * ii` calculates a time point\n- This time point is appended to the `split_time` list\n\nFor example, if `split` is 50 seconds and `nof_chunks` is 3, this loop will add the following to `split_time`:\n- When `ii` is 0: 0 * 50 = 0 seconds\n- When `ii` is 1: 1 * 50 = 50 seconds\n- When `ii` is 2: 2 * 50 = 100 seconds\n\n```python\nsplit_time.append(video_duration)\n```\nAfter the loop, this line adds the total duration of the video to the `split_time` list.\n\nThe purpose of this code is to create a list of time points that can be used to split the video into chunks. Here's what the `split_time` list represents:\n\n- The first element (index 0) is always 0, representing the start of the video.\n- The last element is the total duration of the video.\n- The elements in between represent the starting points of each chunk.\n\nFor example, if the video is 160 seconds long and we're splitting it into 3 chunks, `split_time` might look like this:\n`[0, 53, 106, 160]`\n\nThis means:\n- The first chunk goes from 0 to 53 seconds\n- The second chunk goes from 53 to 106 seconds\n- The third chunk goes from 106 to 160 seconds\n\nThis list of split points can then be used with video processing tools (like `moviepy`, which was imported earlier) to actually split the video into separate files or process it in chunks.","metadata":{}},{"cell_type":"code","source":"# convert to .mp3\nfor ii in range(len(split_time) -1):\n    out_video = \"out_video\"+str(ii)+\".mp4\"\n    ffmpeg_extract_subclip(input_video_file, split_time[ii], split_time[ii+1], targetname = out_video)\n    ffmpeg_extract_audio(out_video, \"output_video_\" + str(ii) + \".mp3\")\n    \nvideo.reader.close()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-08-30T13:55:10.306808Z","iopub.execute_input":"2024-08-30T13:55:10.307234Z","iopub.status.idle":"2024-08-30T13:55:31.808107Z","shell.execute_reply.started":"2024-08-30T13:55:10.307186Z","shell.execute_reply":"2024-08-30T13:55:31.806428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This code is processing the video by splitting it into chunks and converting each chunk to an MP3 audio file. Let's break it down:\n\n```python\nfor ii in range(len(split_time) - 1):\n```\nThis loop runs for each chunk of the video. It goes from 0 to one less than the length of `split_time` because we're using each pair of adjacent times in `split_time` to define a chunk.\n\n```python\n    out_video = \"out_video\"+str(ii)+\".mp4\"\n```\nThis creates a unique filename for each video chunk, like \"out_video0.mp4\", \"out_video1.mp4\", etc.\n\n```python\n    ffmpeg_extract_subclip(input_video_file, split_time[ii], split_time[ii+1], targetname = out_video)\n```\nThis function (from `moviepy.video.io.ffmpeg_tools`) extracts a portion of the video:\n- `input_video_file` is the original video file\n- `split_time[ii]` is the start time of this chunk\n- `split_time[ii+1]` is the end time of this chunk\n- `targetname = out_video` specifies the output file name\n\nThis creates a new video file for each chunk.\n\n```python\n    ffmpeg_extract_audio(out_video, \"output_video_\" + str(ii) + \".mp3\")\n```\nThis function extracts the audio from the video chunk and saves it as an MP3 file:\n- `out_video` is the input (the video chunk we just created)\n- `\"output_video_\" + str(ii) + \".mp3\"` is the output file name (e.g., \"output_video_0.mp3\")\n\n```python\nvideo.reader.close()\n```\nAfter the loop, this line closes the video file that was opened earlier with `VideoFileClip`. This is important for releasing system resources.\n\nIn summary, this code does the following for each chunk of the video:\n1. Creates a unique filename for the video chunk\n2. Extracts that chunk from the original video file\n3. Extracts the audio from that chunk and saves it as an MP3 file\n\nAfter processing all chunks, it closes the original video file.\n\nThis approach allows for processing large videos in smaller pieces, which can be useful for:\n- Working within memory constraints\n- Parallel processing\n- Handling API limitations (like the 25MB limit mentioned earlier)\n- Creating smaller, more manageable files for further processing or analysis\n\nThe resulting MP3 files could then be used for tasks like speech recognition, audio analysis, or transcription.","metadata":{}},{"cell_type":"code","source":"# transcribe with Whisper\ntranscript_all = \"\"\nfor ii in range(len(split_time) - 1):\n    output_audio = \"output_video_\" + str(ii) + \".mp3\"\n    audio_file = open(output_audio, \"rb\")\n    transcript = client.audio.transcriptions.create(model = \"whisper-1\", file = audio_file)\n    transcript_all += transcript.text\n","metadata":{"execution":{"iopub.status.busy":"2024-08-30T14:02:16.561329Z","iopub.execute_input":"2024-08-30T14:02:16.561782Z","iopub.status.idle":"2024-08-30T14:03:11.204734Z","shell.execute_reply.started":"2024-08-30T14:02:16.561749Z","shell.execute_reply":"2024-08-30T14:03:11.203551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This code is using OpenAI's Whisper model to transcribe the audio chunks created in the previous steps. Let's break it down:\n\n```python\ntranscript_all = \"\"\n```\nThis initializes an empty string to store the complete transcript of all audio chunks.\n\n```python\nfor ii in range(len(split_time) - 1):\n```\nThis loop iterates over each audio chunk. The range is the same as in the previous code snippet, corresponding to each chunk of the original video.\n\n```python\n    output_audio = \"output_video_\" + str(ii) + \".mp3\"\n```\nThis creates the filename for each MP3 audio chunk, matching the names created in the previous step.\n\n```python\n    audio_file = open(output_audio, \"rb\")\n```\nThis opens the audio file in binary read mode (\"rb\"). This is necessary because the OpenAI API expects the file to be sent as binary data.\n\n```python\n    transcript = client.audio.transcriptions.create(\n        model=\"whisper-1\", \n        file=audio_file\n    )\n```\nThis uses the OpenAI client (set up earlier) to transcribe the audio:\n- `model=\"whisper-1\"` specifies the Whisper model to use for transcription.\n- `file=audio_file` provides the opened audio file to the API.\n\nThe API call returns a transcript object.\n\n```python\n    transcript_all += transcript.text\n```\nThis appends the transcribed text from this chunk to the `transcript_all` string, building up the complete transcript.\n\nIn summary, this code:\n1. Iterates through each audio chunk\n2. Opens each MP3 file\n3. Sends it to OpenAI's Whisper API for transcription\n4. Appends the resulting transcription to a complete transcript string\n\nThe result is a single string (`transcript_all`) containing the full transcript of the entire video, created by concatenating the transcriptions of each audio chunk.\n\nThis approach allows for transcribing long videos that might exceed API limits if sent as a single file. It processes each chunk separately and combines the results, which is useful for handling large videos or working within API constraints.\n\nAfter this process, `transcript_all` would contain the complete transcription of the original video, which could then be used for further processing, analysis, or display to the user.","metadata":{}},{"cell_type":"code","source":"# save to local file to be used later\nwith open(\"local_transcript.txt\", \"w\") as file:\n    file.write(transcript_all)","metadata":{"execution":{"iopub.status.busy":"2024-08-30T14:08:58.984999Z","iopub.execute_input":"2024-08-30T14:08:58.985504Z","iopub.status.idle":"2024-08-30T14:08:58.992574Z","shell.execute_reply.started":"2024-08-30T14:08:58.985465Z","shell.execute_reply":"2024-08-30T14:08:58.991180Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# extract key points\nencoding = tiktoken.get_encoding(\"cl100k_base\")","metadata":{"execution":{"iopub.status.busy":"2024-08-30T14:09:27.447977Z","iopub.execute_input":"2024-08-30T14:09:27.448432Z","iopub.status.idle":"2024-08-30T14:09:27.453457Z","shell.execute_reply.started":"2024-08-30T14:09:27.448398Z","shell.execute_reply":"2024-08-30T14:09:27.452286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# estimate the cost\n\nmuh_messages = [\n        {\n            \"role\": \"user\",\n            \"content\":f\"give me the key topics from this interview {transcript_all}\" \n        }\n]\n\nnbr = num_tokens_from_message(muh_messages)\nprint(\"prompt tokens will be: \" + str(nbr))\n\nprint(\"price estimate for GPT3.5: \" + str( nbr * 0.0010 / 1000))\nprint(\"price estimate for GPT4: \" + str( nbr * 0.03 / 1000))","metadata":{"execution":{"iopub.status.busy":"2024-08-30T14:09:28.705709Z","iopub.execute_input":"2024-08-30T14:09:28.706228Z","iopub.status.idle":"2024-08-30T14:09:28.720950Z","shell.execute_reply.started":"2024-08-30T14:09:28.706177Z","shell.execute_reply":"2024-08-30T14:09:28.719547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n1. First, a list called `muh_messages` is created. This list contains a single dictionary with two key-value pairs:\n   - \"role\": \"user\"\n   - \"content\": A string that includes \"give me the key topics from this interview\" followed by the content of `transcript_all`\n\n2. The variable `nbr` is assigned the result of calling a function named `num_tokens_from_message` with `muh_messages` as its argument. This function likely counts the number of tokens in the message(s).\n\n3. The code then prints three lines:\n\n   a. The number of prompt tokens:\n      ```python\n      print(\"prompt tokens will be: \" + str(nbr))\n      ```\n      This displays the number of tokens calculated in step 2.\n\n   b. The estimated price for using GPT-3.5:\n      ```python\n      print(\"price estimate for GPT3.5: \" + str( nbr * 0.0010 / 1000))\n      ```\n      This calculates the cost by multiplying the number of tokens by 0.0010 (which represents $0.0010 per 1000 tokens) and dividing by 1000 to get the cost in dollars.\n\n   c. The estimated price for using GPT-4:\n      ```python\n      print(\"price estimate for GPT4: \" + str( nbr * 0.03 / 1000))\n      ```\n      Similar to the GPT-3.5 calculation, but uses 0.03 (which represents $0.03 per 1000 tokens) for GPT-4.\n\nOverall, this code appears to be estimating the cost of processing a transcript using both GPT-3.5 and GPT-4 models, based on the number of tokens in the input message. The pricing used here suggests that GPT-4 is significantly more expensive per token than GPT-3.5.\n","metadata":{}},{"cell_type":"code","source":"response = client.chat.completions.create(\n    model = \"gpt-3.5-turbo\",\n    messages = muh_messages,\n    \n)\n\nprint(response.choices[0].message.content)","metadata":{"execution":{"iopub.status.busy":"2024-08-30T14:09:32.806271Z","iopub.execute_input":"2024-08-30T14:09:32.806692Z","iopub.status.idle":"2024-08-30T14:09:35.415276Z","shell.execute_reply.started":"2024-08-30T14:09:32.806656Z","shell.execute_reply":"2024-08-30T14:09:35.414102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n1. The code is using an API client   to interact with a language model. Let's go through it line by line:\n\n2. ```python\n   response = client.chat.completions.create(\n   ```\n   This line is calling the `create` method of the `chat.completions` object from the client. It's used to generate a chat completion - essentially, to get a response from the AI model.\n\n3. ```python\n   model = \"gpt-3.5-turbo\",\n   ```\n   This specifies which model to use. In this case, it's using \"gpt-3.5-turbo\", which is one of OpenAI's language models known for its efficiency and lower cost compared to GPT-4.\n\n4. ```python\n   messages = muh_messages,\n   ```\n   This is passing the `muh_messages` we saw in the previous code snippet as the input to the model. It contains the user's request along with the transcript.\n\n5. ```python\n   )\n   ```\n   This closing parenthesis ends the `create` method call.\n\n6. ```python\n   print(response.choices[0].message.content)\n   ```\n   After getting the response from the API:\n   - `response.choices` is a list of possible responses.\n   - `[0]` selects the first (and usually only) response.\n   - `.message.content` accesses the content of the message in that response.\n   - The `print` function then outputs this content to the console.\n\nIn summary, this code is sending a request to the GPT-3.5-turbo model with the previously prepared messages, and then printing out the model's response. The response likely contains the key topics from the interview that were requested in the input message.\n","metadata":{}},{"cell_type":"markdown","source":"# Translate to Polish","metadata":{}},{"cell_type":"code","source":"msg_to_translate = response.choices[0].message.content\n\nresp_translation = client.chat.completions.create(\n    model = \"gpt-3.5-turbo\",\n    messages = [\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n        {\"role\": \"user\", \"content\": f\"Translate to Polish this text: {msg_to_translate}\"}\n    ]\n    \n)\n\ntranslation = resp_translation.choices[0].message.content","metadata":{"execution":{"iopub.status.busy":"2024-08-30T14:09:41.414868Z","iopub.execute_input":"2024-08-30T14:09:41.415318Z","iopub.status.idle":"2024-08-30T14:09:44.666077Z","shell.execute_reply.started":"2024-08-30T14:09:41.415281Z","shell.execute_reply":"2024-08-30T14:09:44.664992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. ```python\n   msg_to_translate = response.choices[0].message.content\n   ```\n   This line extracts the content of the message from the previous API response. It's taking the content that we printed in the last code snippet and storing it in a new variable called `msg_to_translate`.\n\n2. ```python\n   resp_translation = client.chat.completions.create(\n   ```\n   This line starts another API call to the chat completions endpoint. This time, it's being used to perform a translation.\n\n3. ```python\n   model = \"gpt-3.5-turbo\",\n   ```\n   Again, we're using the GPT-3.5-turbo model for this task.\n\n4. ```python\n   messages = [\n       {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n       {\"role\": \"user\", \"content\": f\"Translate to Polish this text: {msg_to_translate}\"}\n   ]\n   ```\n   This creates a new list of messages for the API call:\n   - The first message sets the system role, defining the AI as a helpful assistant.\n   - The second message is the user's request, asking for a translation to Polish. It includes the text to be translated (`msg_to_translate`) using an f-string.\n\n5. ```python\n   )\n   ```\n   This closes the `create` method call.\n\n6. ```python\n   translation = resp_translation.choices[0].message.content\n   ```\n   Finally, this line extracts the translated text from the API response and stores it in a variable called `translation`.\n\nIn summary, this code is taking the result from the previous API call (which likely contained the key topics from an interview), and then making another API call to translate that content into Polish. The translated text is then stored in the `translation` variable.\n\nThis approach allows for a two-step process: first extracting information, then translating it, all using the same GPT-3.5-turbo model but with different prompts.","metadata":{}},{"cell_type":"code","source":"print(translation)","metadata":{"execution":{"iopub.status.busy":"2024-08-30T14:09:44.667953Z","iopub.execute_input":"2024-08-30T14:09:44.668320Z","iopub.status.idle":"2024-08-30T14:09:44.674119Z","shell.execute_reply.started":"2024-08-30T14:09:44.668289Z","shell.execute_reply":"2024-08-30T14:09:44.672945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Talk back","metadata":{}},{"cell_type":"code","source":"voice = 'nova'\n\nspeech_file_path = f\"text_{voice}.mp3\"\n\nresponse_audio =  client.audio.speech.create(\n    model = \"tts-1\",\n    voice = voice,\n    input = translation\n    )\n\nresponse_audio.stream_to_file(speech_file_path)","metadata":{"execution":{"iopub.status.busy":"2024-08-30T14:09:47.031315Z","iopub.execute_input":"2024-08-30T14:09:47.031706Z","iopub.status.idle":"2024-08-30T14:09:53.300196Z","shell.execute_reply.started":"2024-08-30T14:09:47.031674Z","shell.execute_reply":"2024-08-30T14:09:53.299094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n1. ```python\n   voice = 'nova'\n   ```\n   This line sets a variable `voice` to the string 'nova'. This likely refers to a specific voice model or style that will be used for text-to-speech conversion.\n\n2. ```python\n   speech_file_path = f\"text_{voice}.mp3\"\n   ```\n   This creates a file path for the output audio file. It uses an f-string to incorporate the `voice` variable into the filename. For example, with `voice` set to 'nova', the file path would be \"text_nova.mp3\".\n\n3. ```python\n   response_audio = client.audio.speech.create(\n   ```\n   This line starts a call to the audio speech creation API. It's likely using OpenAI's text-to-speech service or a similar service.\n\n4. ```python\n   model = \"tts-1\",\n   ```\n   This specifies the text-to-speech model to use. \"tts-1\" is likely a identifier for a specific text-to-speech model.\n\n5. ```python\n   voice = voice,\n   ```\n   This passes the `voice` variable we set earlier as a parameter, specifying which voice to use for the speech synthesis.\n\n6. ```python\n   input = translation\n   ```\n   This provides the text to be converted to speech. It uses the `translation` variable, which from the previous code snippet contains the Polish translation of the original text.\n\n7. ```python\n   )\n   ```\n   This closes the `create` method call.\n\n8. ```python\n   response_audio.stream_to_file(speech_file_path)\n   ```\n   This line takes the audio response from the API and streams it directly to a file. The file path is the one we defined earlier in `speech_file_path`.\n\nIn summary, this code is taking the translated text (which is in Polish based on the previous snippet) and converting it to speech using a text-to-speech API. It's using a voice model called 'nova' and saving the resulting audio as an MP3 file named \"text_nova.mp3\".\n\nThis completes a pipeline that starts with extracting key topics from a transcript, translates those topics to Polish, and finally converts the Polish text to speech.\n","metadata":{}},{"cell_type":"code","source":"IPython.display.Audio(speech_file_path)","metadata":{"execution":{"iopub.status.busy":"2024-08-30T14:09:53.302239Z","iopub.execute_input":"2024-08-30T14:09:53.302617Z","iopub.status.idle":"2024-08-30T14:09:53.329924Z","shell.execute_reply.started":"2024-08-30T14:09:53.302587Z","shell.execute_reply":"2024-08-30T14:09:53.328509Z"},"trusted":true},"execution_count":null,"outputs":[]}]}